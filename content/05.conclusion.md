## Conclusion

Data use collaborations are incredibly diverse in terms of the types of artifacts being shared, the degree to which they are shared, the purposes with which they are shared, not to mention the power dynamics among collaborators. This means that we must attend to the design of the rules and incentive structures that govern human behavior as much as we attend to the design of hardware and software. While there is no one-size-fits-all solution, we can learn from observed research collaborations and reuse patterns of governance systems that worked well for those collaborations when we design new systems of governance, or transition from one system to another. The important thing is that form follows function: governance must be determined by the nature of collaboration desired. For example, large projects require governance campaigns and design, are high impact and rare, and often possess long feedback loops before value creation. Small projects require on-the-ground governance and immediate feedback loops. 

There are limits to the structure-design pattern approach. One is that implementation is messy in reality: there will inevitably be some trial and error, as technology and governance are co-iterated in practice. Exactly how technology and governance combine in actual use will be determined when the project runs. Additionally, institutions within science have longstanding incentives to perform customized governance as a service, which can make traction for new methods difficult. Funder mandates have been quite successful in open access governance and may be necessary in data governance as well. 

Thus by our model we do not mean there is one “right” governance design, but instead that successful designs must share two traits: they should allow collaborators to get going quickly in a legally valid structure, and they should also be flexible enough to change to meet the needs of collaborators — especially in the early stages of design or transition. Turning ad hoc processes into governance design patterns means they can be encoded in software: services and products can integrate some key patterns and variables, supporting implementation in daily practice. 

Our structure-design pattern for data governance pairing sits inside a growing understanding of how the ways that human-centered design can help in policymaking and governance. In addition to this Green Paper, which will map out the landscape of data governance and its mixture into technical platforms, we are in early development for three major projects that take advantage of that mixture. Each draws on Sage’s goals of increasing the scope of responsible sharing, of representative data, to increase the reliability of claims that come out of data analysis. 

Like our structure-design pattern work here, the next stage builds on the way we develop software and other products using human-centered design. The work of using open science to generate reliable claims from representative data (and of sharing both responsibly) remains laborious, manual, and time consuming. We propose to extend data governance into software testing frameworks and information architecture to address this problem.
 
Reliable Analytic Test Framework
Our Reliable Analytic Environment project looks to extend the concept of automated testing frameworks from software testing to create similar functionality to evaluate the reliability of analytical outputs. Instead of looking for software bugs, we will look for reliability bugs and their impacts. These could come from small sample sizes, failure to implement known best practices, and failure to test against known benchmarks.
 
Representative Algorithm Test Framework
We propose to create a testing framework for representativeness in medical research. Drawing on research into social determinants of health and the rapidly increasing public health data sources available, we can begin to craft software services that take a person’s algorithmic designs and test them against public, semi-public, and potentially even semi-private data sets to evaluate the likelihood of under-sampling bias. This will allow data scientists to examine how their code looks beyond their non-representative samples, and see if they are accidentally encoding bias in their work — and, if so, what the impacts are.
 
Information Architecture of Data Governance
For areas such as informed consent, privacy policy, contract negotiation, and data licensing, simply generating and releasing tools and licenses has not been shown to have a nonlinear impact. One reason is that an enormous amount of tacit knowledge is required to use these kinds of tools appropriately, and they are often used in spaces that are distant from the data scientist (i.e., lawyers discuss these tools, not coders). Our IA work will explore how we can learn from libraries and other complex information spaces, so that we can find areas where we need to build tools. Tools could include pedagogical resources (up to and including online courses), software services, and testing environments. 
Epilogue
We envision the integrated technologies, governance structures, and design patterns we describe here as part of a fundamental infrastructure for a robust science commons. It marries the development of technologies for open science with the development of technologies for their governance. In our vision, the science commons infrastructure would connect scientific knowledge — at least in part — across domains and guide the evolution of data science across scholarly paradigms. Every scientist would be afforded access to digital services with which to contribute to and benefit from a scientific knowledge commons and be able, in turn, to manage those services legally and ethically. For assets from data to algorithms to protocols to prose to diagrams, anyone could store, transfer, compute, collaborate, publish, read, verify, and critique. This infrastructure will require the hardware and software to create virtual spaces for data sharing, as well as the governance systems to make data sharing effective, efficient, and responsible. 

Effective governance mechanisms would incentivize high quality scientific work and protect against abuses. For example, virtual spaces could be certified for different purposes: zones of complete openness, zones of privacy, zones that are mixed, and experimental zones that allow for work beyond default rules. Across spaces with different rules, it may also make sense to allow for selective enforcement to stimulate innovative activity in virtual “bohemias.” Such spaces could benefit emergent, quasi-scientific domains (e.g. DIY biology), which need more structure and connection to established fields than they presently have, but not so much that it dulls the novel nature of the work. Like hardware and software, governance would have to be tailored and evolve over time.

Creating a digital infrastructure for the science commons is no small undertaking. But science has always faced a tragedy of the commons. Vannevar Bush wrote in his now infamous text, Science: the Endless Frontier, “there are areas of science in which the public interest is acute but which are likely to be cultivated inadequately if left without more support than will come from private sources.” For the last 75 years, the federal government has stepped in to address this market failure through the National Science Foundation, a constellation of National Laboratories, and other means. “Basic research leads to new knowledge. It provides scientific capital. It creates the fund from which the practical applications of knowledge must be drawn” (Bush, 1945). 

In our science-innovation mythos, the commons was understood narrowly as fundamental scientific knowledge — the “seedcorn” of innovation — and the tragedy of its underproduction was to be solved by public funding of discipline-based, investigator-driven, basic research. But the world has changed over the last 75 years. Notably, there is no longer a market failure for R&D. Private funding of R&D has surpassed federal funding since 1980 and that gap has been steadily growing (National Science Board, 2018), and “innovations often occur that do not require basic or applied research or development” (Congressional Research Service, 2012). Despite the growth of scientific knowledge over the past decades, economic productivity has stagnated; more R&D at universities does not automatically translate into more value in the economy (Arora et al., 2019). Something is missing. The scientific commons has not disappeared, but it has shifted... and so has the tragedy. 

The old commons tragedy was the production of knowledge, with the focus on the product: our metaphorical seed corn. The new commons tragedy is the production of knowledge, with the focus on the production: our metaphorical system of agriculture. Seed corn cannot grow if the topsoil has been eroded, or if a drought has reduced the amount of available water, or if a shifting climate has increased the number or freezing degree days, or if bollweevils eat all of our seedcorn because, though monoculture, our stock was not diverse enough. If collecting more seedcorn is our only tactic, then we may go hungry when our environmental context changes. Instead, we must have a more diverse set of tactics within an overarching, robust strategy of cultivation.

How will the practice of science, itself, operate for the good of society in our new era? We must reconceive the scientific commons as a system and, therefore, pay more attention to what lies between individual sciences: the transdisciplinary infrastructure and boundary-spanning institutions that enable the entire system of knowledge production to function. We must build the tools and practices for integrating different communities of knowledge workers into a larger ecology of knowledge in order to make the system as a whole more productive and more resilient. 

Good governance for everyone is where we propose to begin.
